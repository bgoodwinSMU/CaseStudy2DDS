---
title: "Project 2 DS6306"
author: "Ben Goodwin"
date: "11/29/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "/Users/benjamingoodwin/Desktop/casestudy2DDS/CaseStudy2DDS/") 
```

```{r}
# Project Summary
# 
# Frito-Lay contacted DDSAnalytics concerning it's specialization in talent management solutions. The team at Frito-Lay is especially interested in DDSAnalytics claimed abilities to harness data science by predicting attrition. DDSAnalytics has been tasked with conducting an analysis of existing employee data.
# 
# Specifically, DDSAnalytics will analyze factors that lead to attrition.


# Some project deliverables:
# 
# Top three factors that lead to attrition.
# 
# Identification of trends hidden in the data concerning job role specific trends
# 
# Robust visualization of said trends
# 
# Model for predicting attrition, alongside a .csv file containing predictions for attrition
# 
# Model for salary prediction, alongside a .csv file containing predictions for monthly salary
# 
# I am confident in the validity of this analysis and hope that Frito-Lay determines an appropriate course of action to take based on the work in this R markdown file.

#YouTube link: https://youtu.be/UtNPEyfNsoY

#Execuitive Summary

# In this file we will examine a few questions of interest: 
#   
# 1) Top three factors that contribute to attrition.
# 
# 2) Identification of trends in the data concerning job role specific trends.
# 
# 3) Robust visualization of said trends
# 
# 4) A model for prediction of attrition
# 
# 5) A model for prediction of salaries

# General Conclusions for QOI1:
# 
# Attrition is a tricky variable of interest. When the two groups are plotted, there is visual evidence supporting those who stay with their jobs are very similar to those who leave their jobs. Luckily, using principal component anaylsis (PCA) I was able to derive some important trends between those who stayed and those who left jobs.
# 
# PCA is a technique for dimensionality reduction, and worked well with this dataset as 38 variables were present in the initial dataset. (CaseStudy2-data.txt) The initial impression of the data was that it was quite noisy and contained many similar variables attempting to measure the same thing, and a few variables which did not yeild any results significant for the attrition analysis or for any of the other QOIs.

#General Conclusions for QOI2: 

# From the components and the bi-plot, there are some interesting takeaways about job roles.
# 
# -Job roles tend to cluster around each other, indiciating they each have specific attributes that lend themselves to that job role (maybe not that profound, but certainly can be confirmed after looking at the plot)
# 
# -Managers and research directors tend to be more heavily associated with years of experience.
# 
# -Sales representatives and sales directors are associated with attrition in terms of abosolute of magnitude of their loadings.
# 
# -Interestingly, number of companies worked lands squarely in the middle of the pack and doesn't seem to have mich bearing on job role.
# 
# -Years with current manager doesn't seem to point to job roles in a specific direction, indicating should one wish to pivot, they should develop attributes more in line with the intended role (a decision that could be made based on this chart)


#General Conclusions for QOI3:

#Throughout this file, you will find many visualizations of the data.  Each plot has commentary and adequate visuals to understand the purpose of the chart.

#General Conclusions for QOI4:

# Classification of Attrition
# 
# Since attrition seemed to be hard to visually spot, this presented an interesting problem for classification. Could a classifier examine the data on a level that is unobservable by the human eye? Furthermore, the balance of the data was very off. Only 140 of the 830 employees were indicated as "Yes" for attrition, meaning that 730 of the employees indicated "No" for attrition. This ratio was about .19, meaning that if you guessed that 4 out of 5 employees were "No" for attrition, they could potientially be fairly accurate.
# 
# The solution was to oversample the data to restore balance between the no's and yes's.
# 
# For Bayesian classifcation, the preferred datatype is a factor,so the data was converted to all factors, including the outcome variable, "Attrition." Making this a binary classification model. The Bayesian classifer came in at 81% accuracy, 86% sensitivity, and 76% specificity.
# 
# An additional model was used for classification. Regularized Discriminant Analysis was the second method (This operator performs a regularized discriminant analysis (RDA). for nominal labels and numerical attributes. Discriminant analysis is used to determine which variables discriminate between two or more naturally occurring groups, it may have a descriptive or a predictive objective.). I felt these characteristics were preferred for this data. After analysis I felt the RDA model was better suited, and chose to submit it's predictions for attrition. RDA resulted in 85% accuracy, 87% sensitivity, and 83% specificity. Outperforming the Bayesian classifier on all metrics.

#General Conclusions for QOI5:

# Finally, we discuss salary predictions. A multiple linear regression model was used to achieve desired results. Initially a model was used using all predictors, however this yielded a R^2 value that was impossibly high. A plot was then generated using the Caret package which visually showed the importance of each varible in the model. The following variables were included in the final model: job level, totalworkingyears, yearswithcurrmanager, distance from home. The linear model was generated and each of the variables were considered significant at the P<0.05 level. Addtionally the model itself was significant with P<0.05.

#In conclusion, we looked at factors that contribute to attrition, examined job role specific trends, predicted attrition using RDA, and predicted monthly income using a linear model. I hope these results can be used in a meaningful way.  Thanks Frito-lay.


```



```{r}
#############################################
#                                           #
#               Libraries                   #
#                                           #
#############################################

#This section contains libraries necessary for the functionality of this analysis

#Missingness maps
library(naniar)

#For reading .xlsx
library(readxl)

#General data manipulation
library(dplyr)
library(tidyverse)
library(psych)

#Plot generations
library(ggplot2)
library(GGally)
#Plotting PCA 
library(ggfortify)
library(pca3d)
library(FactoMineR)
library(factoextra)

#For oversampling
library(imbalance)

#For Ml
library(caret)
library(e1071)

```






```{r}
#############################################
#                                           #
#           Read in data                    #
#                                           #
#############################################

#This section adds the files into the R project space so that the analysis can be performed. 

#Read in primary data ("CaseStudy2-data.txt")
primaryData <- read.table("CaseStudy2-data.txt",sep = ",",header = TRUE)
#Peek data
#head(primaryData)

###############Read in other datasets###############

#Case study 2 classification example dataset ("Case2PredictionsClassifyEXAMPLE.txt")
predictionsClassify <- read.table("Case2PredictionsClassifyEXAMPLE.txt",sep = ",",header = TRUE)

#Case study 2 predictions regression example dataset ("Case2PredictionsRegressEXAMPLE.txt")
predictionsRegression <- read.table("Case2PredictionsRegressEXAMPLE.txt",sep = ",",header = TRUE)

#Case study 2 compset no attrition dataset ("CaseStudy2CompSet No Attrition.txt")
compsetNoAttrition <- read.table("NoAttrition.txt",sep = ",",header = TRUE)

#Case study 2 compset no salary dataset ("CaseStudy2CompSet No Salary.xlsx")
compsetNoSalary <- read_excel("CaseStudy2CompSet No Salary.xlsx")

```



```{r}
#############################################
#                                           #
#       EDA and Data Preperation            #
#                Part 1                     #
#############################################

#EDA is necessary to visually examine the data and begin to learn about the ways
#of this dataset.  First we will start with missingness.

#Examine primary dataset for missingness
primaryDatMiss <- vis_miss(primaryData)
primaryDatMiss

#Examine Case study 2 classification example dataset
predictionClassiftMiss <- vis_miss(predictionsClassify)
predictionClassiftMiss

#Case study 2 predictions regression example dataset
predictionsRegressionMiss <- vis_miss(predictionsRegression)
predictionsRegressionMiss

#Case study 2 compset no attrition dataset 
compsetNoAttritionMiss <- vis_miss(compsetNoAttrition)
compsetNoAttritionMiss

#Case study 2 compset no salary dataset
compsetNoSalaryMiss <- vis_miss(compsetNoSalary)
compsetNoSalaryMiss



```

```{r}

#############################################
#                                           #
#       EDA and Data Preperation            #
#                Part 2                     #
#                                           #
#############################################

#EDA is necessary to visually examine the data and begin to learn about the ways of this dataset

#Convert all CHR variables to factors to examine pairs data
primaryData_factor <- primaryData %>%
  mutate_if(sapply(primaryData, is.character), as.factor)

#Convert all CHR variables to ints for COV 
primaryData_int <- primaryData_factor %>%
  mutate_if(sapply(primaryData_factor, is.factor), as.integer)


#Look at dataset from with a wide lense
describe(primaryData_factor)

####Look at some of the variables as histograms####

#Histogram of age
hist(primaryData_factor$Age)

#Histogram of working years
hist(primaryData_factor$TotalWorkingYears)

#Histogram of Monthly Income
hist(primaryData_factor$MonthlyIncome)

####Look at some of the variables as plots####

#Look at relationship between monthly income and wokring years
plot(primaryData_factor$TotalWorkingYears,primaryData_factor$MonthlyIncome)

#Look at relationship between monthly income and attrition
plot(primaryData_factor$Attrition,primaryData_factor$MonthlyIncome)


#Look at relationship between distance from home and attrition
plot(primaryData_factor$Attrition,primaryData_factor$DistanceFromHome)

#Look at relationship between years since last promotion and attrition
plot(primaryData_factor$Attrition,primaryData_factor$YearsSinceLastPromotion)

#Look at relationship between distance job satisfaction and attrition
plot(primaryData_factor$Attrition,primaryData_factor$JobSatisfaction)

#Look at relationship between environment satisfaction and attrition
plot(primaryData_factor$Attrition,primaryData_factor$EnvironmentSatisfaction)

#Look at relationship between marital status and attrition
plot(primaryData_factor$Attrition~primaryData_factor$MaritalStatus)

#Look at Attrition levels
plot(primaryData_factor$Attrition)

plot(primaryData_factor$Attrition,primaryData_factor$DistanceFromHome)




```


```{r}
#############################################
#                                           #
#            Identify factors               #
#              that lead to                 #
#                attrition                  #
#                                           #
#                                           #
#############################################

#First method will be to use PCA (principal component analysis)

#Lets look at the covairance matrix of the attrition dataset and attempt to scale it all

#A bit of data preperation
pcaDat <- primaryData_int[,c(2:4,6:9,12:13,15:20,22:36)]
#pcaDat

PCAdat_factor <- primaryData_int[,c(2:4,6:9,12:13,15:20,22:36)]
#PCAdat_factor[,c(2,3,4,7,9,12,14,17,18)] <- as.integer(PCAdat_factor[,c(2,3,4,7,9,12,14,17,18)])
PCAdat_factor$Attrition <- as.factor(PCAdat_factor$Attrition)
PCAdat_factor$Attrition <- factor(PCAdat_factor$Attrition,levels = c(1,2),labels = c("No","Yes"))


S <- cov(pcaDat[,c(1,3:30)])
#S

#Examine total variance, (sum of the eigenvalues of S)
sum(diag(S))

#Compute the eigenvalues and corresponding eigenvectors of S
s.eigen <- eigen(S)
s.eigen

#Use eigenvalues to find the proportion of the total variance explained by the components
for (s in s.eigen$values) {
  print(s / sum(s.eigen$values))
}

#It would seem that the first two principal components account for nearly 99% of the total variance

#Create a plot to determine the proportion of variance explained by each subsequential eigenvalue
plot(s.eigen$values, xlab="Eigenvalue Number",ylab="Eigenvalue Size",main="Scree Graph")+lines(s.eigen$values)


####Use R packages to confirm results####
quitters.pca <- prcomp(pcaDat[,c(1,3:30)])
#quitters.pca

#Components reported by package are equal to earlier computations

#Look at proportion of variance explained by components
summary(quitters.pca)

#Plot the principal components
pca.plot <- autoplot(quitters.pca,data=PCAdat_factor,colour='Attrition',loadings=TRUE,loadings.colour="blue",loadings.label=TRUE) 
pca.plot

#The points of the two groups are clustered somewhat, however there appears to be more attrition at the right of the graph.  The data does not appear to depart widely from multivariate normality.  

#Create new df for R
rDat <- pcaDat[,c(1,3:16,18:21,23:30)]
#rDat

#Lets use R instead of S 
R <- cor(rDat)
#R

#Again find Eigenvalues and Eigenvectors for R
r.eigen <- eigen(R)
#r.eigen


#Compute proportion of total variance explained by the eigenvalues
for (r in r.eigen$values) {
  print(r/sum(r.eigen$values))
  
}

#PCA (scaled)
quitters.pca.scaled <- prcomp(rDat,scale = TRUE)
#quitters.pca.scaled

#Summary of scaled 
summary(quitters.pca.scaled)

#Plot elbow plot to determine components required
plot(r.eigen$values, xlab="Eigenvalue Number",ylab="Eigenvalue Size",main="Scree Graph")+lines(r.eigen$values)

#Look at Visualized data
pca.plot.scaled <- autoplot(quitters.pca.scaled,data = PCAdat_factor,colour='Attrition',loadings=TRUE,loadings.colour="blue",loadings.label=TRUE)
pca.plot.scaled



#Check out a 3D plot to attempt to determine best components to use
#pca3d(quitters.pca.scaled,group=PCAdat_factor$Attrition,legend = "topleft",biplot = TRUE,biplot.vars = 3)


####Plots of PCs####

#First plot using autoplot
autoplot(quitters.pca.scaled,data = PCAdat_factor,colour='Attrition',loadings=TRUE,loadings.colour="blue",loadings.label=TRUE,x=1,y=2)

#Other plots using ggbiplot
#biplot with ellipse, pc1,2
p <- ggbiplot::ggbiplot(quitters.pca.scaled,ellipse = TRUE,circle = FALSE,groups = PCAdat_factor$Attrition,choices = 1:2,varname.size = 3,varname.adjust = 2,alpha = 0.5)+ggtitle("PCA of Attrition Dataset PC1,PC2")+theme_minimal()
p

####PC1 Interpretation####
#High positive loadings for years at company, years in current role, and .4 (highest) in total working years,years with current manager, monthly income, job level
#This component seems to measure employee stability, and seemingly perhaps overall success at a given company
#This component is the primary PC and explains 17.35% of the variation in the data

####PC2 Interpretation####
#Large negative loadings on age and number of companies employee worked at, this component measures an employees attrition based on age
#This component is the secondary PC and explains 7.0% of the variation in the data

#biplot without ellipse pc1,2
p2 <- ggbiplot::ggbiplot(quitters.pca.scaled,ellipse = FALSE,circle = FALSE,groups = PCAdat_factor$Attrition,choices = 1:2,varname.size = 3,varname.adjust = 2,alpha = 0.5)+ggtitle("PCA of Attrition Dataset PC1,PC2")+theme_minimal()
p2

####PC2 Interpretation####
#Large negative loadings on age and number of companies employee worked at, this component measures an employees attrition based on age
#This component is the secondary PC and explains 7.0% of the variation in the data

#biplot with ellipse, pc2,3
p3 <- ggbiplot::ggbiplot(quitters.pca.scaled,ellipse = TRUE,circle = FALSE,groups = PCAdat_factor$Attrition,choices = 2:3,varname.size = 3,varname.adjust = 2,alpha = 0.5)+ggtitle("PCA of Attrition Dataset PC2,PC3")+theme_minimal()
p3

#biplot without ellipse, pc2,3
p4 <- ggbiplot::ggbiplot(quitters.pca.scaled,ellipse = FALSE,circle = FALSE,groups = PCAdat_factor$Attrition,choices = 2:3,varname.size = 3,varname.adjust = 2,alpha = 0.5)+ggtitle("PCA of Attrition Dataset PC2,PC3")+theme_minimal()
p4

####PC3 Interpretation####
#Very large negative loadings on percent salary hike and performance rating.  This component seems to measure an employees recordabable performance.  
##This component is the tertiary PC and explains 6.75% of the variation in the data, making it rougly as important as 1

#biplot with ellipse, pc3,4
p5 <- ggbiplot::ggbiplot(quitters.pca.scaled,ellipse = TRUE,circle = FALSE,groups = PCAdat_factor$Attrition,choices = 3:4,varname.size = 3,varname.adjust = 2,alpha = 0.5)+ggtitle("PCA of Attrition Dataset PC3,PC4")+theme_minimal()
p5

#biplot without ellipse, pc3,4
p6 <- ggbiplot::ggbiplot(quitters.pca.scaled,ellipse = FALSE,circle = FALSE,groups = PCAdat_factor$Attrition,choices = 3:4,varname.size = 3,varname.adjust = 2,alpha = 0.5)+ggtitle("PCA of Attrition Dataset PC3,PC4")+theme_minimal()
p6

####PC4 Interpretation####
#Negative loadings on department, martial status, and performance ratings.  This component appears to measure employees with roles that could potentially be all consuming
#This component is the fourth PC and explains 6.33% of the variation in the data

#################################
#Note!
#These four PC's only explain 37.46232% of the variation in the data, I will use and additional 11 PC's for further analysis.  I have not included loading plots for these as the interpretation is too nuanced. 

#15 PCs capture 81% of the variance in the data (0.1735757+0.07028831+0.06750148+0.06325877+0.05967773+0.04353646+0.04226411+0.04068733+0.03963922+0.03889302+0.03744872+0.036015730+0.03450615+0.03405034+0.03339357)

#Useful line for sorting PC's
#sort(abs(quitters.pca.scaled$rotation[,2]),decreasing = TRUE)

# barplot((quitters.pca.scaled$rotation[,1]),main="PC 1 Loadings Plot",las=2,+abline(0.30,0))


```

```{r}
####PCA concerning Attrition####
#prep data
pcaDatPlots <- pcaDat[,-c(17,22)]
pcaDatPlots <- pcaDatPlots[order(pcaDatPlots$Attrition),]
pcaDatPlots <- pcaDatPlots[,-c(2)]

#Perform PCA
quitters.pca.scaledPlots <- prcomp(pcaDatPlots,scale = TRUE)

s <- summary(quitters.pca.scaledPlots)
```



```{r}
#Plot PC1 PC2
fviz_eig(quitters.pca.scaledPlots, addlabels=TRUE, hjust = -0.3,
               linecolor ="red",ncp = 15) + theme_minimal()

# Create groups
pch.group <- c(rep(21, times=730), rep(22, times=140))
col.group <- c(rep("gold", times=730), rep("skyblue2", times=140))

# Plot individuals
plot(quitters.pca.scaledPlots$x[,1], quitters.pca.scaledPlots$x[,2], xlab=paste("PCA 1 (", round(s$importance[2]*100, 1), "%)", sep = ""), ylab=paste("PCA 2 (", round(s$importance[5]*100, 1), "%)", sep = ""), pch=pch.group, col="black", bg=col.group, cex=1, las=1,asp=1)
# Add grid lines
abline(v=0, lty=2, col="grey50")
abline(h=0, lty=2, col="grey50")

# Add legend
legend("bottomleft", legend=c("No Attrition", "Attrition"), col="black", pt.bg=c("gold", "skyblue2"), pch=c(21, 22), pt.cex=1.5)

# Get individuals (observations) as a matrix
tab <- matrix(c(quitters.pca.scaledPlots$x[,1], quitters.pca.scaledPlots$x[,2]), ncol=2)
# Calculate correlations
c1 <- cor(tab[1:729,])
c2 <- cor(tab[730:840,])


# Load package
library(ellipse)
# Plot ellipse
polygon(ellipse(c1*(max(abs(quitters.pca.scaledPlots$rotation))*1), centre=colMeans(tab[1:729,]), level=0.95), col=adjustcolor("gold", alpha.f=0.25), border="gold")
polygon(ellipse(c2*(max(abs(quitters.pca.scaledPlots$rotation))*1), centre=colMeans(tab[730:870,]), level=0.95), col=adjustcolor("skyblue2", alpha.f=0.25), border="skyblue2")

# Create matrix of x coordinates (PC1) and multiply by 10
l.x <- cbind(quitters.pca.scaledPlots$rotation[,1][c(11, 13, 17, 12)]) * 10
# y coordinates (PC2)
l.y <- cbind(quitters.pca.scaledPlots$rotation[,2][c(11,13,17,12)]) * 10

# Add arrows to biplot
arrows(x0=0, x1=l.x, y0=0, y1=l.y, col="red", length=0.15, lwd=2)
# Labels
text(l.x, l.y, labels=rownames(l.x) , col="black", pos=c(2, 3, 4, 1), offset=1, cex=1.2)

###Interpretation of PC1 and PC2####
#The first component is positively correlated with total working years, years at company, job level, monthly income.  This suggests the give variables vary together and when one goes down, the others decrease as well.  The component could be considered a primary measure of career length and longevity and well as a measure of success.

#The second component is mostly correlated with number of companies worked, and age, but in a negative direction.  Years with current manager and years in current role are correlated with the second component in the positive direction, which indicates that as number of companies and age decrease, years with current manager and years in current role increase.  

#Looking at the biplot, we can see the loadings that point in the direction of the attrition ellipse.  In terms of the first component, we can see that Job Role and Marriage Status point more towards the attrition ellipse.  The same with Job Satisfaction and percent salary hike for the second component. 

```

```{r}
# Plot PC2 PC3
plot(quitters.pca.scaledPlots$x[,2], quitters.pca.scaledPlots$x[,3], xlab=paste("PCA 2 (", round(s$importance[5]*100, 1), "%)", sep = ""), ylab=paste("PCA 3 (", round(s$importance[8]*100, 1), "%)", sep = ""), pch=pch.group, col="black", bg=col.group, cex=1, las=1,asp=0.5)
# Add grid lines
abline(v=0, lty=2, col="grey50")
abline(h=0, lty=2, col="grey50")

# Add legend
legend("bottomleft", legend=c("No Attrition", "Attrition"), col="black", pt.bg=c("gold", "skyblue2"), pch=c(21, 22), pt.cex=1.5)

# Get individuals (observations) as a matrix
tab <- matrix(c(quitters.pca.scaledPlots$x[,2], quitters.pca.scaledPlots$x[,3]), ncol=2)
# Calculate correlations
c1 <- cor(tab[1:729,])
c2 <- cor(tab[730:840,])


# Load package
library(ellipse)
# Plot ellipse
polygon(ellipse(c1*(max(abs(quitters.pca.scaledPlots$rotation))*1), centre=colMeans(tab[1:729,]), level=0.95), col=adjustcolor("gold", alpha.f=0.25), border="gold")
polygon(ellipse(c2*(max(abs(quitters.pca.scaledPlots$rotation))*1), centre=colMeans(tab[730:870,]), level=0.95), col=adjustcolor("skyblue2", alpha.f=0.25), border="skyblue2")

# Create matrix of x coordinates (PC1) and multiply by 10
l.x <- cbind(quitters.pca.scaledPlots$rotation[,2][c(13, 26, 3, 11)]) * 10
# y coordinates (PC2)
l.y <- cbind(quitters.pca.scaledPlots$rotation[,3][c(13,26,3,11)]) * 10

# Add arrows to biplot
arrows(x0=0, x1=l.x, y0=0, y1=l.y, col="red", length=0.15, lwd=3)
# Labels
text(l.x, l.y, labels=rownames(l.x) , col="black", pos=c(2, 3, 1, 4), offset=1, cex=1.2)

###Interpretation of PC3####

#The third component is most correlated with performance rating and percent salary hike, both in a negative direction.  Department and job role are correlated with the third component in a positive direction, suggesting that as performance rating and percent salary hike decrease, department and job role increase.

#Looking at the biplot, we can see the loadings that point in the direction of the attrition ellipse.  In terms of the third component, we can see that department and job role point more towards the attrition ellipse, this is the second biplot that job role has pointed towards attrition, suggesting this may be a variable of interest concerning attrition.

```

```{r}
# Plot PC3 PC4
plot(quitters.pca.scaledPlots$x[,3], quitters.pca.scaledPlots$x[,4], xlab=paste("PCA 3 (", round(s$importance[8]*100, 1), "%)", sep = ""), ylab=paste("PCA 4 (", round(s$importance[11]*100, 1), "%)", sep = ""), pch=pch.group, col="black", bg=col.group, cex=1, las=1,asp=1)
# Add grid lines
abline(v=0, lty=2, col="grey50")
abline(h=0, lty=2, col="grey50")

# Add legend
legend("topleft", legend=c("No Attrition", "Attrition"), col="black", pt.bg=c("gold", "skyblue2"), pch=c(21, 22), pt.cex=1.5)

# Get individuals (observations) as a matrix
tab <- matrix(c(quitters.pca.scaledPlots$x[,3], quitters.pca.scaledPlots$x[,4]), ncol=2)
# Calculate correlations
c1 <- cor(tab[1:729,])
c2 <- cor(tab[730:840,])


# Load package
library(ellipse)
# Plot ellipse
polygon(ellipse(c1*(max(abs(quitters.pca.scaledPlots$rotation))*1), centre=colMeans(tab[1:729,]), level=0.95), col=adjustcolor("gold", alpha.f=0.25), border="gold")
polygon(ellipse(c2*(max(abs(quitters.pca.scaledPlots$rotation))*1), centre=colMeans(tab[730:870,]), level=0.95), col=adjustcolor("skyblue2", alpha.f=0.25), border="skyblue2")

# Create matrix of x coordinates (PC1) and multiply by 10
l.x <- cbind(quitters.pca.scaledPlots$rotation[,3][c(14, 3, 13, 1)]) * 10
# y coordinates (PC2)
l.y <- cbind(quitters.pca.scaledPlots$rotation[,4][c(14, 3, 13, 1)]) * 10

# Add arrows to biplot
arrows(x0=0, x1=l.x, y0=0, y1=l.y, col="red", length=0.15, lwd=3)
# Labels
text(l.x, l.y, labels=rownames(l.x) , col="black", pos=c(1, 3, 2, 3), offset=1, cex=1.2)

###Interpretation of PC4####

#The fourth component is most correlated with stock option level.  Martial Status and percent salary hike are correlated with the fourth component, but in a negative direction.  This suggest that as stock option level increases, martial status and percent salary hike decrease.  

#Looking at the biplot, we can see the loadings that point in the direction of the attrition ellipse.  In terms of the the fourth component, we can see that marital status and age point more towards the attrition ellipse, this is the second biplot that maritial status has pointed towards attrition, suggesting this may be another variable of interest concerning attrition.

```



```{r}
####Loadings Plots####
#PC1
c.pc1 <- ifelse(quitters.pca.scaledPlots$rotation[,1] > 0, yes="green2", no="red2")
n.pc1 <- ifelse(quitters.pca.scaledPlots$rotation[,1] > 0, yes=-0.01, no=quitters.pca.scaledPlots$rotation[,1]-0.01)
par(mar=c(8,3,2,1)) # Set margins
b1 <- barplot(quitters.pca.scaledPlots$rotation[,1], main="PC 1 Loadings Plot", col=c.pc1, las=2, axisnames=FALSE,ylim = c(-0.3,0.5))
abline(h=0) # Add horizontal line
text(x=b1, y=n.pc1, labels=names(quitters.pca.scaledPlots$rotation[,1]), adj=1, srt=90, xpd=TRUE) # Add variable names


#PC2
c.pc2 <- ifelse(quitters.pca.scaledPlots$rotation[,2] > 0, yes="green2", no="red2")
n.pc2 <- ifelse(quitters.pca.scaledPlots$rotation[,2] > 0, yes=-0.01, no=quitters.pca.scaledPlots$rotation[,2]-0.01)
par(mar=c(8,3,2,1)) # Set margins
b2 <- barplot(quitters.pca.scaledPlots$rotation[,2], main="PC 2 Loadings Plot", col=c.pc2, las=2, axisnames=FALSE)
abline(h=0) # Add horizontal line
text(x=b2, y=n.pc2, labels=names(quitters.pca.scaledPlots$rotation[,2]), adj=1, srt=90, xpd=TRUE) # Add variable names

#PC3
c.pc3 <- ifelse(quitters.pca.scaledPlots$rotation[,3] > 0, yes="green2", no="red2")
n.pc3 <- ifelse(quitters.pca.scaledPlots$rotation[,3] > 0, yes=-0.01, no=quitters.pca.scaledPlots$rotation[,3]-0.01)
par(mar=c(8,3,2,1)) # Set margins
b3 <- barplot(quitters.pca.scaledPlots$rotation[,3], main="PC 3 Loadings Plot", col=c.pc3, las=2, axisnames=FALSE,ylim = c(-0.6,0.6))
abline(h=0) # Add horizontal line
text(x=b3, y=n.pc3, labels=names(quitters.pca.scaledPlots$rotation[,3]), adj=1, srt=90, xpd=TRUE) # Add variable names

#PC4
c.pc4 <- ifelse(quitters.pca.scaledPlots$rotation[,4] > 0, yes="green2", no="red2")
n.pc4 <- ifelse(quitters.pca.scaledPlots$rotation[,4] > 0, yes=-0.01, no=quitters.pca.scaledPlots$rotation[,4]-0.01)
par(mar=c(8,3,2,1)) # Set margins
b4 <- barplot(quitters.pca.scaledPlots$rotation[,4], main="PC 4 Loadings Plot", col=c.pc4, las=2, axisnames=FALSE,ylim = c(-0.4,0.6))
abline(h=0) # Add horizontal line
text(x=b4, y=n.pc4, labels=names(quitters.pca.scaledPlots$rotation[,4]), adj=1, srt=90, xpd=TRUE) # Add variable names

#PC5
c.pc5 <- ifelse(quitters.pca.scaledPlots$rotation[,5] > 0, yes="green2", no="red2")
n.pc5 <- ifelse(quitters.pca.scaledPlots$rotation[,5] > 0, yes=-0.01, no=quitters.pca.scaledPlots$rotation[,5]-0.01)
par(mar=c(8,3,2,1)) # Set margins
b5 <- barplot(quitters.pca.scaledPlots$rotation[,5], main="PC 5 Loadings Plot", col=c.pc5, las=2, axisnames=FALSE,ylim = c(-0.6,0.6))
abline(h=0) # Add horizontal line
text(x=b5, y=n.pc5, labels=names(quitters.pca.scaledPlots$rotation[,5]), adj=1, srt=90, xpd=TRUE) # Add variable names


#PC6
c.pc6 <- ifelse(quitters.pca.scaledPlots$rotation[,6] > 0, yes="green2", no="red2")
n.pc6 <- ifelse(quitters.pca.scaledPlots$rotation[,6] > 0, yes=-0.01, no=quitters.pca.scaledPlots$rotation[,6]-0.01)
par(mar=c(8,3,2,1)) # Set margins
b6 <- barplot(quitters.pca.scaledPlots$rotation[,6], main="PC 6 Loadings Plot", col=c.pc6, las=2, axisnames=FALSE,ylim = c(-0.4,0.6))
abline(h=0) # Add horizontal line
text(x=b6, y=n.pc6, labels=names(quitters.pca.scaledPlots$rotation[,6]), adj=1, srt=90, xpd=TRUE) # Add variable names


```



```{r}
####PCA concerning Job Role Trends####
#prep data
pcaDatPlotsRoles <- pcaDat[,-c(17,22)]
pcaDatPlotsRoles <- pcaDatPlotsRoles[order(pcaDatPlotsRoles$JobRole),]
pcaDatPlotsRoles <- pcaDatPlotsRoles[,-c(12)]

#Perform PCA
rolePCA <- prcomp(pcaDatPlotsRoles,scale = TRUE,center = TRUE)

#Save summary object
s <- summary(rolePCA)
#s$rotation
```

```{r}
#Scree plot
fviz_eig(rolePCA, addlabels=TRUE, hjust = -0.3,
               linecolor ="red",ncp = 15) + theme_minimal()


```

```{r}
# Create groups
pch.group <- c(rep(25, times=76), rep(15, times=27), rep(21, times=153), rep(22, times=51), rep(23, times=87), rep(24, times=51), rep(25, times=172), rep(21, times=200), rep(22, times=53))
col.group <- c(rep("green", times=76), rep("brown", times=27), rep("red", times=153), rep("purple", times=51), rep("cyan", times=87), rep("gold", times=51), rep("coral", times=172), rep("deeppink", times=200), rep("midnightblue", times=53))




# Plot individuals
plot(rolePCA$x[,1], rolePCA$x[,2], xlab=paste("PCA 1 (", round(s$importance[2]*100, 1), "%)", sep = ""), ylab=paste("PCA 2 (", round(s$importance[5]*100, 1), "%)", sep = ""), pch=pch.group, col="black", bg=col.group, cex=1, las=1,asp=1)
# Add grid lines
abline(v=0, lty=2, col="grey50")
abline(h=0, lty=2, col="grey50")


# Add legend
legend("topleft", legend=c("Healthcare Representative", "Human Resources","Laboratory Technician","Manager","Manufacturing Director","Research Director","Research Scientist","Sales Executive","Sales Representative"), col="black", pt.bg=c("green", "brown","red","purple","cyan","gold","coral","deeppink","midnightblue"), pch=c(25,15,21,22,23,24,25, 21,22), pt.cex=1.5,cex = 0.5)

# Get individuals (observations) as a matrix
tab <- matrix(c(rolePCA$x[,1], rolePCA$x[,2]), ncol=2)
# Calculate correlations
c1 <- cor(tab[1:56,])
c2 <- cor(tab[57:83,])
c3 <- cor(tab[84:256,])
c4 <- cor(tab[257:287,])
c5 <- cor(tab[288:394,])
c6 <- cor(tab[395:445,])
c7 <- cor(tab[446:617,])
c8 <- cor(tab[618:815,])
c9 <- cor(tab[816:870,])

# Load package
library(ellipse)
# Plot ellipse
polygon(ellipse(c1*(max(abs(quitters.pca.scaledPlots$rotation))*1), centre=colMeans(tab[1:56,]), level=0.95), col=adjustcolor("green", alpha.f=0.25), border="green")
polygon(ellipse(c2*(max(abs(quitters.pca.scaledPlots$rotation))*1), centre=colMeans(tab[57:83,]), level=0.95), col=adjustcolor("brown", alpha.f=0.25), border="brown")
polygon(ellipse(c1*(max(abs(quitters.pca.scaledPlots$rotation))*1), centre=colMeans(tab[84:256,]), level=0.95), col=adjustcolor("red", alpha.f=0.25), border="red")
polygon(ellipse(c1*(max(abs(quitters.pca.scaledPlots$rotation))*1), centre=colMeans(tab[257:287,]), level=0.95), col=adjustcolor("purple", alpha.f=0.25), border="purple")
polygon(ellipse(c1*(max(abs(quitters.pca.scaledPlots$rotation))*1), centre=colMeans(tab[288:394,]), level=0.95), col=adjustcolor("cyan", alpha.f=0.25), border="cyan")
polygon(ellipse(c1*(max(abs(quitters.pca.scaledPlots$rotation))*1), centre=colMeans(tab[395:445,]), level=0.95), col=adjustcolor("gold", alpha.f=0.25), border="gold")
polygon(ellipse(c1*(max(abs(quitters.pca.scaledPlots$rotation))*1), centre=colMeans(tab[446:617,]), level=0.95), col=adjustcolor("coral", alpha.f=0.25), border="coral")
polygon(ellipse(c1*(max(abs(quitters.pca.scaledPlots$rotation))*1), centre=colMeans(tab[618:815,]), level=0.95), col=adjustcolor("deeppink", alpha.f=0.25), border="deeppink")
polygon(ellipse(c1*(max(abs(quitters.pca.scaledPlots$rotation))*1), centre=colMeans(tab[816:870,]), level=0.95), col=adjustcolor("midnightblue", alpha.f=0.25), border="midnightblue")

which.max(rolePCA$rotation[,1])
which.min(rolePCA$rotation[,1])

which.max(rolePCA$rotation[,2])
which.min(rolePCA$rotation[,2])

sort((rolePCA$rotation[,1]),decreasing = FALSE)

# Create matrix of x coordinates (PC1) and multiply by 10
l.x <- cbind(rolePCA$rotation[,1][c(2, 21,15,27)]) * 10
# y coordinates (PC2)
l.y <- cbind(rolePCA$rotation[,2][c(2, 21,15,27)]) * 10

# Add arrows to biplot
arrows(x0=0, x1=l.x, y0=0, y1=l.y, col="red", length=0.15, lwd=2)
# Labels
text(l.x, l.y, labels=rownames(l.x) , col="black", pos=c(2, 3, 4, 1), offset=1, cex=1.2)




```

```{r}

#Analysis using Naive Bayes and Regularized Discriminant Analysis

###############################################################################
#Printing functions
printALL=function(model){
  trainPred=predict(model, newdata = train, type = "class")
  trainTable=table(train$Attrition, trainPred)
  testPred=predict(model, newdata=test, type="class")
  testTable=table(test$Attrition, testPred)
  trainAcc=(trainTable[1,1]+trainTable[2,2])/sum(trainTable)
  testAcc=(testTable[1,1]+testTable[2,2])/sum(testTable)
  message("Contingency Table for Training Data")
  print(trainTable)
  message("Contingency Table for Test Data")
  print(testTable)
  message("Accuracy")
  print(round(cbind(trainAccuracy=trainAcc, testAccuracy=testAcc),3))
}

ggplotConfusionMatrix <- function(m){
  mytitle <- paste("Accuracy", percent_format()(m$overall[1]),
                   "Sensitivity",percent_format()(m$byClass[1]),"Specificity",percent_format()(m$byClass[2]))
  p <-
    ggplot(data = as.data.frame(m$table) ,
           aes(x = Prediction, y = Reference)) +
    geom_tile(aes(fill = log(Freq)), colour = "white") +
    scale_fill_gradient(low = "white", high = "steelblue") +
    geom_text(aes(x = Reference, y = Prediction, label = Freq)) +
    theme(legend.position = "none") +
    ggtitle(mytitle)
  return(p)
}

###############################################################################

#Read in primary data ("CaseStudy2-data.txt")
primaryData <- read.table("/Users/benjamingoodwin/Desktop/casestudy2DDS/CaseStudy2DDS/CaseStudy2-data.txt",sep = ",",header = TRUE)

#Convert all CHR variables to factors to examine pairs data
primaryData_factor <- primaryData %>%
  mutate_if(sapply(primaryData, is.character), as.factor)


#Convert all CHR variables to ints for COV 
primaryData_int <- primaryData_factor %>%
  mutate_if(sapply(primaryData_factor, is.factor), as.integer)

nnDat <- primaryData_int[,-c(1,5,10,11,14,21,23,24,28)]

#Over sample to correct for imbalance
nnDat <- oversample(nnDat,classAttr = "Attrition",method = "ADASYN")


nnDat$Attrition <- (ifelse(nnDat$Attrition==1,"No","Yes"))
nnDat$Attrition <- as.factor(nnDat$Attrition)

set.seed(107)


inTrain <- createDataPartition(y=nnDat$Attrition,p=0.75,list = FALSE)
class(nnDat$Attrition)
levels(nnDat$Attrition)
training <- nnDat[inTrain,]
testing <- nnDat[-inTrain,]

ctrl <- trainControl(method = "repeatedcv", repeats = 3,classProbs = TRUE, summaryFunction = twoClassSummary)

noAttDs <- read.table("/Users/benjamingoodwin/Desktop/casestudy2DDS/CaseStudy2DDS/noAttrition.txt",sep = ",",header = TRUE)

nnDat1 <- noAttDs
#Remove unneeded cols
#noAttDs <- noAttDs[,-c(4,9,10,13,20,22,23,27)]

#Convert all CHR variables to factors to examine pairs data
nnDat1 <- nnDat1 %>%
  mutate_if(sapply(nnDat1, is.character), as.factor)




#Make factors
noAttDs <- noAttDs %>%
  mutate_if(sapply(noAttDs, is.integer), as.factor)
#Remove unneeded cols
noAttDs <- noAttDs[,-c(4,9,10,13,20,22,23,27)]


#Convert all CHR variables to ints for COV 
nnDat1 <- nnDat1 %>%
  mutate_if(sapply(nnDat1, is.factor), as.integer)

rdaGrid = data.frame(gamma = (0:4)/4, lambda = 3/4)
set.seed(123)
rdaFit <- train(Attrition ~ .,data = training,method = "rda",tuneGrid = rdaGrid,trControl = ctrl,metric = "ROC")
rdaFit

rdaClasses <- predict(rdaFit, newdata = testing)
cfm <- confusionMatrix(rdaClasses, testing$Attrition)
cfm
ggplotConfusionMatrix(cfm)


other1 <- predict(rdaFit,newdata = nnDat1,type = "raw")
#view(other1)


newDf <- noAttDs
newDf$Attrition=other1

#View(newDf)

newDf <- newDf[,c(1,28)]

out <- write.csv(newDf,"~/Documents/Case2PredictionsGoodwinAttrition.csv",row.names = FALSE)


################################################################################

####Factor with over sampling, model 2####

##Data prep for NB
#Read in primary data ("CaseStudy2-data.txt")
primaryData <- read.table("/Users/benjamingoodwin/Desktop/casestudy2DDS/CaseStudy2DDS/CaseStudy2-data.txt",sep = ",",header = TRUE)

#Convert all CHR variables to factors to examine pairs data
primaryData_factor <- primaryData %>%
  mutate_if(sapply(primaryData, is.character), as.factor)


#Convert all CHR variables to ints for COV 
primaryData_int <- primaryData_factor %>%
  mutate_if(sapply(primaryData_factor, is.factor), as.integer)

nnDat <- primaryData_int[,-c(1,5,10,11,14,21,23,24,28)]

#Create DF
dataAllFact = primaryData_int[,-c(1,5,10,11,14,21,23,24,28)]


#Over sample to correct for imbalance
newDataAllFact <- oversample(dataAllFact,classAttr = "Attrition",method = "ADASYN")

#Oversample changes all to numeric, revert to factor
newDataAllFactor <- newDataAllFact %>%
  mutate_if(sapply(newDataAllFact, is.integer), as.factor)

newDataAllFactor$Attrition <- (ifelse(newDataAllFactor$Attrition==1,"No","Yes"))
newDataAllFactor$Attrition <- as.factor(newDataAllFactor$Attrition)

#Check out the imbalance ratio
imbalanceRatio(newDataAllFactor,"Attrition")

#Do the stuff for NB
#Set seed to easily duplicate results
set.seed(7267166)

#Split training and testing data
trainIndex=createDataPartition(newDataAllFactor$Attrition, p=0.70)$Resample1
train=newDataAllFactor[trainIndex, ]
test=newDataAllFactor[-trainIndex, ]

#Create classifier
NBclassfier=naiveBayes(Attrition~., data=train)

#call print function
printALL(NBclassfier)

#Generate CM
nb_train_predict <- predict(NBclassfier,test[,names(test) !="Attrition"])
cfm <- confusionMatrix(nb_train_predict,test$Attrition)
cfm

#Look at plot
ggplotConfusionMatrix(cfm)


###############################################################################
#Make predictions, with NB model
noAttDs <- read.table("/Users/benjamingoodwin/Desktop/casestudy2DDS/CaseStudy2DDS/noAttrition.txt",sep = ",",header = TRUE)
#Make factors
noAttDs <- noAttDs %>%
  mutate_if(sapply(noAttDs, is.integer), as.factor)
#Remove unneeded cols
noAttDs <- noAttDs[,-c(4,9,10,13,20,22,23,27)]



nb_train_predictNewDS <- predict(NBclassfier,noAttDs)
nb_train_predictNewDS

table(nb_train_predictNewDS)

newDf <- noAttDs
newDf$Attrition=nb_train_predictNewDS


newDf <- newDf[,c(1,28)]
newDf

```

```{r}
primaryData <- read.table("/Users/benjamingoodwin/Desktop/casestudy2DDS/CaseStudy2DDS/CaseStudy2-data.txt",sep = ",",header = TRUE)
salaryDatNoinfo <- compsetNoSalary

salaryDat <- primaryData[,c(16,20,30,7,36)]



salaryDatlm <- lm(MonthlyIncome~JobLevel+TotalWorkingYears+YearsWithCurrManager+DistanceFromHome,data = salaryDat)
summary(salaryDatlm)

RSS <- c(crossprod(salaryDatlm$residuals))
MSE <- RSS / length(salaryDatlm$residuals)
RMSE <- sqrt(MSE)
sig2 <- RSS / salaryDatlm$df.residual

plotlm <- train(MonthlyIncome~JobLevel+TotalWorkingYears+YearsWithCurrManager+DistanceFromHome,data=salaryDat,method="lm",trainControl=tc)


ggplot(varImp(plotlm))

##########EDA for Salary##########
salaryDatEDA <- primaryData[,-c(1,5,10,11,14,21,23,24,28)]
samp <- createDataPartition(salaryDatEDA$MonthlyIncome,p=0.8,list = FALSE)
training <- salaryDatEDA[samp,]
testing <- salaryDatEDA[-samp,]

tc <- trainControl(method = "cv",number = 10)
lm1_cv <- train(MonthlyIncome~.,data=salaryDatEDA,method="lm",trainControl=tc)
lm1_cv
ggplot(varImp(lm1_cv))

predictedSal <- predict(salaryDatlm,salaryDatNoinfo)
table(predictedSal)

newDf <- salaryDatNoinfo
newDf$MonthlyIncome=predictedSal
#View(newDf)

newDf <- newDf[,c(1,36)]

out <- write.csv(newDf,"~/Documents/Case2PredictionsGoodwinSalary.csv",row.names = FALSE)
```



